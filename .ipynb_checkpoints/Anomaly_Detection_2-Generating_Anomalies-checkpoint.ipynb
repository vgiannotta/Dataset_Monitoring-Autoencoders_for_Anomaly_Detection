{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b68637",
   "metadata": {},
   "source": [
    "# Generating the anomalies  \n",
    "\n",
    "Now that we have bootstrapped enough sample data, we need to fabricate some anomaly records. Otherwise, all of our data will be based on healthy updates, and we won't have any examples of anomalies on which to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda8be13-0078-480d-a8a0-7a22d77e7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "import numpy as np, numpy.random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4975e7",
   "metadata": {},
   "source": [
    "## Approximating failure event metadata\n",
    "\n",
    "To start, we'll take 5% of the rows in our bootstrapped data and artificially shrink or inflate the numbers.  \n",
    "\n",
    "Anomaly events are updates where:  \n",
    "- The `total_rows` or `errors` are greater than +2 standard deviations from the mean (for `errors`), or less than -2 standard deviations from the mean (for all others)\n",
    "    - It is important to note that some of these records have columns that are dependent of one another. So if we change the number of `total_rows` then we should adjust the number of `rows_updated` and `rows_created` accordingly.\n",
    "- The `error_count` is non-zero  \n",
    "\n",
    "We need to keep in mind that the seasonality we've identified – ie the Sunday / Monday effect – is *not* an anomaly. We should look for anomalies on these days too, understanding that the anomalistic values could be different than on other weekdays.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb272fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in actuals and bootstrapped data\n",
    "df = pd.read_csv('./data/revisions_ACTUALS.csv')\n",
    "df['update_date'] = pd.to_datetime(df['update_date'])\n",
    "\n",
    "bootstrapped_df = pd.read_csv('./data/revisions_BOOTSTRAPPED.csv')\n",
    "bootstrapped_df['date'] = pd.to_datetime(bootstrapped_df['date'])\n",
    "\n",
    "# Generate a sample of records that we'll turn into anomalies\n",
    "anomalies = bootstrapped_df.sample(frac=0.05, random_state=42)\n",
    "anomalies['is_anom'] = 1\n",
    "anomalies['anomaly_type'] = None\n",
    "\n",
    "# Ensure that the bootstrapped data `rows_updated` and `rows_created` sum up to `total_rows`\n",
    "anomalies['rows_created'] = anomalies['total_rows'].apply(lambda x: np.random.randint(0, x))\n",
    "anomalies['rows_updated'] = anomalies['total_rows'] - anomalies['rows_created']\n",
    "\n",
    "# anomalies.to_csv('./data/raw_anomalies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa1404",
   "metadata": {},
   "source": [
    "##### Steps taken to generate and format the anomalies\n",
    "\n",
    "- 10 records: Zeroed out all continuous variables\n",
    "- 10 records: -1 std dev from mean for  `total_rows`, with `rows_updated`, `rows_created`, and `errors` updated accordingly.\n",
    "- 10 records: -2 std dev from mean for  `total_rows`, with `rows_updated`, `rows_created`, and `errors` updated accordingly.\n",
    "    - When values were <=0, I entered very small numbers.\n",
    "- 10 records: +1 std dev from mean for `errors`\n",
    "- 9 records: +2 std dev from mean for `errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9379e40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>rows_updated</th>\n",
       "      <th>rows_created</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29599.450</td>\n",
       "      <td>9262.050</td>\n",
       "      <td>20323.400</td>\n",
       "      <td>14.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18729.524</td>\n",
       "      <td>5920.923</td>\n",
       "      <td>12877.728</td>\n",
       "      <td>24.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1327.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>742.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.250</td>\n",
       "      <td>1475.000</td>\n",
       "      <td>1500.250</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40124.500</td>\n",
       "      <td>12088.000</td>\n",
       "      <td>27841.500</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42772.750</td>\n",
       "      <td>13377.250</td>\n",
       "      <td>29046.250</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44016.000</td>\n",
       "      <td>14816.000</td>\n",
       "      <td>30986.000</td>\n",
       "      <td>93.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_rows  rows_updated  rows_created  errors\n",
       "count      20.000        20.000        20.000  20.000\n",
       "mean    29599.450      9262.050     20323.400  14.000\n",
       "std     18729.524      5920.923     12877.728  24.251\n",
       "min      1327.000         0.000       742.000   0.000\n",
       "25%      2500.250      1475.000      1500.250   0.750\n",
       "50%     40124.500     12088.000     27841.500   6.000\n",
       "75%     42772.750     13377.250     29046.250  10.000\n",
       "max     44016.000     14816.000     30986.000  93.000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When pre-processing the data for modeling, we should reference the descriptive statistics of the actuals, \n",
    "# ranther than the bootstrapped dataset.\n",
    "\n",
    "cols = ['total_rows', 'rows_updated', 'rows_created', 'errors']\n",
    "df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e82546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tot_rows_std_dev = df.total_rows.std()\n",
    "errors_std_dev = df.errors.std()\n",
    "\n",
    "### Zeroing out all continuous variables\n",
    "\n",
    "anomaly_1 = anomalies[1:101]\n",
    "\n",
    "for col in cols:\n",
    "    anomaly_1[col] = 0\n",
    "    \n",
    "# Annotate anomalies with an anomaly type description\n",
    "anomaly_1['anomaly_type'] = \"Dataset published no records\"\n",
    "\n",
    "\n",
    "### -1 std dev from mean for `total_rows`, with `rows_updated`, `rows_created`, and `errors`\n",
    "#                                                                                   updated accordingly.\n",
    "anomaly_2 = anomalies[101:201]\n",
    "\n",
    "# Subtract std dev from total and correct for negative numbers\n",
    "anomaly_2['total_rows'] = anomaly_2['total_rows'].apply(lambda x: max(x - tot_rows_std_dev, 0))\n",
    "anomaly_2['rows_created'] = anomaly_2['total_rows'].apply(lambda x: np.random.randint(0, x) if x > 0 else 0)\n",
    "anomaly_2['rows_updated'] = anomaly_2['total_rows'] - anomaly_2['rows_created']\n",
    "# anomaly_2['rows_created'] = anomaly_2['total_rows'].where((anomaly_2['total_rows'] - anomaly_2['rows_updated']) > 0, other=0)\n",
    "\n",
    "# Assuming here that, if `total_rows` goes down by a standard deviation, then the errors will too\n",
    "anomaly_2['errors'] = anomaly_2['errors'].apply(lambda x: max(x - errors_std_dev, 0))\n",
    "anomaly_2['anomaly_type'] = \"Minus approx. 1 standard deviation in `total_rows`\"\n",
    "\n",
    "\n",
    "### -2 std dev from mean for `total_rows`, with `rows_updated`, `rows_created`, and `errors`\n",
    "#                                                                                   updated accordingly.\n",
    "anomaly_3 = anomalies[201:301]\n",
    "\n",
    "anomaly_3['total_rows'] = anomaly_3['total_rows'].apply(lambda x: max((x - tot_rows_std_dev*2), 0))\n",
    "anomaly_3['rows_created'] = anomaly_3['total_rows'].apply(lambda x: np.random.randint(0, x) if x > 0 else 0)\n",
    "anomaly_3['rows_updated'] = anomaly_3['total_rows'] - anomaly_3['rows_created']\n",
    "anomaly_3['errors'] = anomaly_3['errors'].where((anomaly_3['errors'] - errors_std_dev*2) > 0, other=0)\n",
    "anomaly_3['anomaly_type'] = \"Minus approx. 2 standard deviations in 'total_rows'\"\n",
    "\n",
    "\n",
    "### +1 std dev from mean for `errors`\n",
    "\n",
    "anomaly_4 = anomalies[301:401]\n",
    "\n",
    "anomaly_4['errors'] = anomaly_4['errors'] + np.random.randint(errors_std_dev, errors_std_dev*1.5)\n",
    "anomaly_4['anomaly_type'] = \"Plus approx. 1 standard deviation in 'errors'\"\n",
    "\n",
    "\n",
    "### +2 or more std dev from mean for `errors`\n",
    "\n",
    "anomaly_5 = anomalies[401:]\n",
    "\n",
    "anomaly_5['errors'] = anomaly_5['errors'] + np.random.randint(errors_std_dev*2, errors_std_dev*3.5)\n",
    "anomaly_5['anomaly_type'] = \"Plus approx. 2 (or more) standard deviation in 'errors'\"\n",
    "\n",
    "\n",
    "### Concatenate records\n",
    "frames = [anomaly_1, anomaly_2, anomaly_3, anomaly_4, anomaly_5]\n",
    "\n",
    "anomalies_clean = pd.concat(frames)\n",
    "# anomalies_clean.to_csv('./data/formatted_anomalies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c004cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rows</th>\n",
       "      <th>rows_updated</th>\n",
       "      <th>rows_created</th>\n",
       "      <th>errors</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>axis_label</th>\n",
       "      <th>is_anom</th>\n",
       "      <th>anomaly_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-23</th>\n",
       "      <td>31814.000</td>\n",
       "      <td>3210.000</td>\n",
       "      <td>28604</td>\n",
       "      <td>12.000</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Friday 2024-02-23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-22</th>\n",
       "      <td>32641.000</td>\n",
       "      <td>7499.000</td>\n",
       "      <td>25142</td>\n",
       "      <td>28.000</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday 2024-02-22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-21</th>\n",
       "      <td>27080.000</td>\n",
       "      <td>17965.000</td>\n",
       "      <td>9115</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday 2024-02-21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-20</th>\n",
       "      <td>33074.000</td>\n",
       "      <td>2722.000</td>\n",
       "      <td>30352</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday 2024-02-20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-19</th>\n",
       "      <td>2092.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>2039</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday 2024-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_rows  rows_updated  rows_created  errors       date  \\\n",
       "date                                                                    \n",
       "2024-02-23   31814.000      3210.000         28604  12.000 2024-02-23   \n",
       "2024-02-22   32641.000      7499.000         25142  28.000 2024-02-22   \n",
       "2024-02-21   27080.000     17965.000          9115   5.000 2024-02-21   \n",
       "2024-02-20   33074.000      2722.000         30352   8.000 2024-02-20   \n",
       "2024-02-19    2092.000        53.000          2039  11.000 2024-02-19   \n",
       "\n",
       "           day_of_week            axis_label  is_anom anomaly_type  \n",
       "date                                                                \n",
       "2024-02-23      Friday     Friday 2024-02-23        0          NaN  \n",
       "2024-02-22    Thursday   Thursday 2024-02-22        0          NaN  \n",
       "2024-02-21   Wednesday  Wednesday 2024-02-21        0          NaN  \n",
       "2024-02-20     Tuesday    Tuesday 2024-02-20        0          NaN  \n",
       "2024-02-19      Monday     Monday 2024-02-19        0          NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix schema of bootstrapped dataset so it can be merged with anomalies, and merge\n",
    "\n",
    "anomalies_clean = anomalies_clean.set_index(pd.to_datetime(anomalies_clean['date']))\n",
    "\n",
    "bootstrapped_df = bootstrapped_df.set_index(pd.to_datetime(bootstrapped_df['date']))\n",
    "bootstrapped_df['is_anom'] = 0\n",
    "bootstrapped_df['is_anom'] = bootstrapped_df['is_anom'].astype('int64')\n",
    "bootstrapped_df_copy = bootstrapped_df\n",
    "\n",
    "merged = pd.concat([bootstrapped_df_copy, anomalies_clean])\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0155ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('./data/merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd78b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
